%
% File ranlp2015.tex

%Contact iva@lml.bas.bg

%Based on style for ACL 2010 by
% jshin@csie.ncnu.edu.tw or pkoehn@inf.ed.ac.uk
%%
%% Based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{ranlp2015}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}

\usepackage{mdwlist}
%\setlength\titlebox{6.5cm}    % You can expand the title box if you
% really have to

\title{Determining Environmental Context from Fictional Narratives}

\iffalse
\author{Leon\\
  University of Sheffield\\
  {\tt email1@domain1.com}  \And
  Nanna\\
  Aarhus University\\
  {\tt  email2@domain2.com}}
\fi

\date{}

\begin{document}
\maketitle
\begin{abstract}
Experiencing a narrative can be made more enjoyable and powerful by increasing the level of the immersion in the story.
This can be achieved through contextual cues, such as sounds and images.
In order to provide these cues automatically, we attempt to detect parts of the environment described in a fictional narrative.
We present three machine learning approaches to this problem, compared to a rule-engineered baseline, and evaluate them over a dataset of fictional texts.
In addition, we analyse the performance of this system over the output of a text-to-speech system taking the same narratives as input.
This audio dataset is made available.
The system is able to recognise environmental context and respond appropriately.
\end{abstract}


\section{Introduction}

Non-verbal cues are important to improving the experience of a narrative. 
For example, adding sound qualitatively impacts the recipient's mood, and is useful for increasing immersion and positive narrative experiences~\cite{ermi2005fundamental,madden2009collaborative,huiberts2010captivating}.
An immersive environment is most engaging when participants believe their actions affect the environment; reliable and responsive cues such as sounds are important for this~\cite{bobick1999kidsroom}.
However, providing such cues can be an expensive manual process, and many textual narratives do not have accompanying contextual media such as background sounds or images.
An automatic approach could be taken to building such context.
The research question we address is: how can we automatically identify in narratives environments and events that can be associated with external cues?

Taking narratives as input, we attempt to determine what the appropriate environmental component of the context is, which can then be used to provide cues (such as ambient sounds).
There is a diverse range of potential environments from which cues can be generated, even in a constrained corpus of narratives.
In addition, effects (e.g. video or audio cues) are required for surprise events described in a story, like an approaching horse or a thunderstorm.
This is similar to streamed topic extraction~\cite{allan2002introduction,preotiuc2012trendminer}.
We determine a corpus, frame the task by giving a specific set of environments for which cues are available, and then evaluate system performance over this dataset.
Finally, we create a new language resource of audio recordings and automatic transcriptions, used to evaluate the system on input closer to that it might receive when operating in real-time.



\section{Method}

\subsection{Dataset}
Our ideal requirements are that a dataset be structures as instances, each being a focused passage of text, with most containing descriptions of environments or events.
For this dataset, we used paragraphs from a set of fantasy role-playing books.%~\cite{fangs,crypt,poe,sswamp}.
%HIDDEN FOR REVIEW
Each paragraph is set in a distinct location, each possibly combined with the description of an event, making manual environment annotation simple and distinct.
In comparison, the bounds of passages of text relevant to a particular cue are harder to detemine in running narrative text from e.g. a fictional novel .
The set of potential environmental items in this genre is:

%\begin{itemize*}
%\item Mountain
%\item Hill
%\item Forest
%\item Swamp
%\item Windy
%\item Blizzard
%\item Rain
%\item Lightning
%\item Stream
%\item River
%\item Campfire
%\item Night
%\item Meadow
%\item Road
%\item Town
%\item Crowd
%\item Tavern
%\item Underground
%\item Trotting horse
%\item Galloping horse
%\end{itemize*}

\begin{quote}
{\bf Environments:} Mountain; Hill; Forest; Swamp; Meadow; Road; Town; Crowd; Tavern; Underground.

{\bf Ambience:} Windy; Blizzard; Rain; Lightning; Stream; River; Campfire; Night.

{\bf Events:} Trotting horse; Galloping horse; Thunder
\end{quote}

Paragraphs were labelled with one or more of these labels by a human annotator.
In total, 203 paragraphs were labelled, with 13884 words.

\subsection{Spoken dataset}
An eventual use of this system is to provide automatic sound effects in real-time for a story that is read out loud by a human narrator.
As a result, it should operate well on the output of a speech recognition system.
Paragraphs were read by an English native speaker, and recorded.
A speech recognition system~\cite{lamere2003design} then interpreted these readings and generated a textual version of each paragraph.
The labels used in the text input corpus were then associated with these outputs.
This constitutes the transcribed dataset.

\subsection{Baseline}
As a baseline, we use a gazetteer trigger words that match the name of the cue.
If a word occurs in a candidate passage, then that cue is triggered.
For example, if there is a cue named ``swamp", the passage ``He marches through the swamp, sweating from his brow" will trigger that cue using the baseline system.

\subsection{Features and Classification}

We take a variety of approaches.
Firstly, we try a bag-of-words representation using a multinomial Bayes classifier.
In addition, we represent paragraphs as average vectors in n-dimensional space by taking the cosine product of embeddings of words in the paragraph, and then learn a binary SVM for each cue based on these representations.
We used Collobert and Weston[] embeddings.

The genre used to generate these had a significant effect on result quality.
For example, using embeddings generated from two billion Google News articles, the top-ranking non-punctuation match for the sentence \emph{``The going underfoot becomes muddier, until eventually you reach an area where bulrushes tower over your head."} was the phrase {\em Maria\_Sharapova} -- not an intuitively relevant result.
News is intrinsically constrained in topic and style, and out-of-domain for fictional narratives.
Therefore, we used embeddings learned from the multi-topic Brown corpus, which includes large amounts of narrative and fictional text.


LD feature extraction~\cite{lui2011cross} + nbayes; LD motivated by diversity in subsets of environments encountered per story (e.g. some stories set mostly in woodland, others in a town)

We note that false positives have a higher penalty than false negatives.
It is disruptive to receive the wrong cue.
For example, hearing battle noises when one should hear a babbling brook (false positive) is detrimental, and worse than hearing nothing (false negative).
In order to bias classifications in this direction, we experiment with the SVM Cost parameter~\cite{vapnik?joachims?} and also evaluate with both F1 and F2.


\section{Results}

Our evaluation is using precision and recall.
This is not a plain multi-way classification task; spurious cues and missed cues are both possible, as are multiple cues per text passage.

\section{Related Work}


ML doc classification~\cite{sebastiani2002machine}.

NN good at binary doc classification~\cite{derczynski2006machine}.

SVM doc classification~\cite{isa2008text}.

\section{Conclusion}

\iffalse
\section*{Acknowledgments}
This project has received funding from the European Unionâ€™s Seventh Framework Programme for research, technological development and demonstration under grant agreement No. 611233, \textsc{Pheme}.
ah, was anything funding this? could anything be associated with this?? ahhh, erm
\fi

\bibliographystyle{acl}
\bibliography{rpg-scene}

\end{document}
